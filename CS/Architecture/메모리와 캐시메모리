* RAM의 종류와 특징
- RAM : 휘발성 저장장치. RAM의 용량이 크면 프로그램을 보조기억장치에서 많이 미리 가져다 놓을 수 있기에, 프로그램의 실행 속도가 빨라진다.
- DRAM(Dynamcic RAM) : 동적 RAM 즉, 시간이 지나면 데이터가 점차 사라지는 RAM. 재활성화 과정이 필요. **주로 말하는 메모리로 사용하는 RAM.**
                       근데도 주로 쓰이는 이유는 소비전력이 낮고, 저렴하고, 집적도가 높아 대용량으로 설계가 가능하기 때문!
- SRAM(Static RAM) : 정적 RAM 즉, 저장된 데이터가 사라지지 않는 RAM.(그렇다고 전원이 꺼져도 유지된다는 말은 아님! 날라감. 휘발성임). 재활성화 필요없고 속도도 빠름.
                     하지만 SRAM보다 DRAM이 많이 쓰이는 이유는, DRAM의 장점이 SRAM의 단점이기 때문... -> 그래서 SRAM은 캐시메모리로 쓰임!
- SDRAM(Synchronous Dynamic RAM) : SRAM과는 관계없다. 싱크 -> 뭐랑 싱크? -> 클럭 신호와 싱크! 즉, 클럭 신호와 동기화 된 발전된 DRAM.
                                   클럭 신호에 맞춰 동작하며, 클럭마다 CPU와 정보를 주고받을 수 있는 DRAM이다.
- DDR SDRAM(Double Data Rate SDRAM) : 대역폭(Data Rate)을 넓혀 속도를 빠르게 만든 SDRAM. 최근 가장 많이 사용된다.(대역폭 : 데이터를 주고받는 길의 너비)
                                      그런의미에서 SDR SDRAM(Single Data Rate SDRAM)은, 한 클럭당 데이터를 하나씩 주고받는 SDRAM.
                                      DDR2 SDRAM - SDR보다 2배 넓음 / DDR3 SDRAM - DDR2 보다 2배 넓음. SDR보다 8배 넓음. / DDR4 ... 즉, SDR과 비교하려면 지수승 하면됨.

-----------------------------------------------------------------------------------------------------------------------
* 메모리의 주소 공간
[논리 주소, 물리 주소, MMU, 베이스 레지스터, 한계 레지스터]

- 논리 주소 : CPU와 실행중인 프로그램이 사용하는 주소. 프로그램의 시작 주소로부터 떨어진 거리.
- 물리 주소 : 하드웨어적으로 메모리상의 주소.
>> CPU와 실행중인 프로그램이 메모리에 접근하려면 같은 주소 체계를 사용해야 의사소통이 가능하겠지? 
   그래서 논리 주소를 물리 주소로 변환해줘야 하는데, 그것을 수행하는 것이 MMU.

- MMU(Memory Management Unit) : 메모리 관리 유닛. 
- 베이스 레지스터 : 프로그램의 메모리상 시작 물리 주소를 저장하는 레지스터.
- 한계 레지스터 : 프로그램의 메모리상의 크기 라고도 볼 수 있다. 

** 종합
CPU가 메모리의 주소 공간에 접근하기 위해서는 CPU와 실행중인 프로그램이 사용하는 논리 주소를 메모리가 사용하는 물리 주소로 변환시켜야 하는데, 
MMU가 CPU의 베이스 레지스터에 저장된 값과 CPU의 논리 주소 값을 더하여 논리 주소를 물리 주소로 변환시켜 메모리의 주소 공간에 접근할 수 있게 해준다.
{ 베이스 레지스터 값 + 논리 주소 = 물리 주소 }
이 때, 하나의 프로그램의 메모리 상 주소 공간의 크기를 한계 레지스터가 갖고 있는데, 논리 주소는 한계 레지스터에 저장된 값보다 크면 안된다.
논리 주소가 한계 레지스터에 저장된 값보다 클 경우, 다른 프로그램의 주소 공간에 침범하게 되어 인터럽트가 발생한다.

즉, CPU와 실행중인 프로그램이 메모리에 접근하는 과정은 아래와 같다.
{ 
  CPU(or 실행중인 프로그램)에서 메모리에 접근하고 싶음
  -> 논리 주소가 한계 레지스터에 저장된 값보다 작으면 MMU로 논리 주소 전달(크면 인터럽트)
  -> MMU에서 CPU의 베이스 레지스터에 저장된 값과 전달받은 논리 주소를 더하여 물리 주소로 변환
  -> 해당 물리 주소를 가진 프로그램에 CPU가 접근!(접근해서 메모리를 변경하든지... 삭제하든지 등등 함)
}

-----------------------------------------------------------------------------------------------------------------------
* 캐시 메모리
[저장장치 계층구조, 캐시 메모리, 캐시 적중률, 참조 지역성의 원리]

- 저장 장치 계층 구조(= 메모리 계층구조, Memory Hierarchy) : 'CPU와 얼마나 가까운가'를 기준으로 저장 장치들(메모리들)을 계층적으로 나타낼 수 있다.
                                                            { <빠름, 비쌈, 작음> 레지스터 <-> 메모리 <-> 보조기억장치 <느림, 쌈, 큼> }
- 캐시 메모리(Cache Memory) : CPU와 메모리 사이에 위치한 SRAM 기반의 저장 장치. CPU의 연산속도와 메모리 접근 속도의 차이를 극복하기 위해 등장.
                              CPU가 빠르게 쓸 수 있도록 자주 쓰는 데이터들을 메모리에서 가져와 저장 해 놓음. 편의점 같은 느낌.
                              코어(CPU)와 가장 가까운 L1, 그다음 L2, 그다음 L3 캐시가 있다.
                              { <빠름, 비쌈, 작음> 레지스터 <-> L1 <-> L2 <-> L3 <-> 주기억장치 <-> 보조기억장치 <느림, 쌈, 큼> }
- 캐시 적중률 : 캐시메모리가 가져온 데이터가 CPU에서 활용될 확률. (캐시 히트 횟수 / 캐시 히트 횟수 + 캐시 미스 횟수)

- 참조 지역성의 원리 : CPU가 메모리에 접근할 때의 주된 경향을 바탕으로 만들어진 원리
                      (시간 지역성 : 최근에 접근했던 메모리 공간에 또 접근하는 경향 / 공간 지역성 : 접근했던 메모리 공간의 주변부를 또 접근하는 경향)
